# Feature-Selection-Using-Genetic-Algorithm
This project demonstrates the use of Genetic Algorithm (GA) for selecting potential features to improve the accuracy of classification models. Feature selection is a crucial step in data mining, and selecting relevant features can significantly improve the performance of classification algorithms.

## Getting Started
To get started with the project, you will need to install the following packages:

Python 3.0 or higher
Scikit-learn,
Numpy, Matplotlib, Pandas

## Dataset
The project uses the Breast Cancer dataset for comparing the accuracy of different classification algorithms before and after applying GA. The dataset contains information about breast cancer tumors and has a total of 569 instances with 30 features.

## Usage
To run the feature selection algorithm, use file Genetic_Algorithm_Feature_Selection.ipynb
This will execute the GA algorithm on the Breast Cancer dataset and select the most relevant features for classification. The selected features are then used to train different classifiers, including RandomForest, Decision Tree, AdaBoost, and Linear SVM. The accuracy of each classifier is reported both before and after feature selection.

## Results
The results of the feature selection algorithm show that by using GA to select the most relevant features, the accuracy of the classification models can be improved by up to 2.09%. RandomForest classifier was used to compare the accuracy of the models before and after feature selection. The results show that the accuracy of the models significantly improved after applying feature selection.

## Conclusion
In conclusion, this project demonstrates the use of GA for feature selection, which can significantly improve the performance of classification models. By selecting the most relevant features, the accuracy of the models can be improved, which is important in real-world applications. The project can be further extended to explore other datasets and classification algorithms.
